---
title: "Text analysis with quanteda - Presentation"
author: "Federico Mammana & Kathryn Malchow"
date: "04/11/2021"
output:  
  html_document:
    code_folding: show
    df_print: paged
    highlight: tango
    number_sections: no
    theme: cosmo
    toc: no
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## What is quanteda?

quanteda is an R package to perform a variety of natural language processing tasks: corpus management, tokenization, analysis, visualization.

→ *quanteda is to text analysis what dplyr and tidyr are to data wrangling*

In quanteda, text is processed as:

- corpus → after having converted text data in corpus format (through the corpus function) we can work on it with quanteda; a corpus holds documents separately from each other.

- tokens → usually each word in a text, but also single characters or sentences if we want

- document-feature matrix (“dfm”) → the analytical unit in which perform analysis; text documents are organized in matrices, with original texts as rows and features as columns. “Features” are more generally defined than “terms”, as they may be raw terms, stemmed terms, terms without stopwords, etc.

![Document Feature Matrix](..\14-FedericoMammana-Quanteda-\DFM Pic.png)

## Why use quanteda?

quanteda is built to be faster and more efficient than any other R or Python package for processing large textual data. Infrastructure on three main pillars:

- stringi package for text processing

- Matrix package for sparse matrix objects

- computationally intensive processing (e.g. for tokens) handled in parallelized C++

**Intuitive, powerful, and flexible**


## 

Now lets see text preprocessing workflow and some functions!

## Loading Text Data into R

```{r, echo = TRUE, results='hide', message=FALSE}
library(readtext) # companion package to Quanteda to read text (.txt) files or comma-separated-value (.csv) files
library(quanteda) # for making a corpus and the rest of our text processing
```


### Read in text

```{r, echo=TRUE}
austen_texts = readtext("data/Austen_texts/*.txt", 
                       docvarsfrom= "filenames", dvsep = "_",
                       docvarnames = c("Author", "Book"))
austen_texts
```


### Create a corpus

```{r, echo=TRUE}
book_corpus = corpus(austen_texts)
summary(book_corpus)

```


## Preprocessing

### Tokenize the text

```{r, echo = TRUE}

text <- c("I <3 little pumpkins! OMG they're so cute.")


tokens(text, what = "sentence")
tokens(text, what = "character")
text_token = tokens(text, what = "word") #default
text_token
```


### Remove punctuation, etc within tokens() function

```{r, echo = TRUE}
tokens(text,
remove_punct = TRUE,
remove_numbers = FALSE,
remove_symbols = TRUE)
```


###  Make lower case

```{r, echo = TRUE}
# char_tolower(text) before tokenizing

tokens_tolower(text_token) #after tokenizing
```


### You can also keep acronyms by adding: keep_acronyms = TRUE

```{r, echo = TRUE}
#char_tolower(text, keep_acronyms = TRUE) before tokenizing

tokens_tolower(text_token, keep_acronyms = TRUE)
```


### Removing Stop Words

```{r, echo=TRUE}
tokens_remove(text_token, stopwords("en"))

```


### Removing other unwanted words

```{r, echo=TRUE}
tokens_remove(text_token, c("pumpkins", "cute"))
```


### Word Stemming

```{r, echo=TRUE}

dip_text = c("When I dip, he dips, we are dipping.")

dip_token = tokens(dip_text)

tokens_wordstem(dip_token)
```


## KeyWords in Context, a cool function

```{r, echo=TRUE}
lr_text = c("Three Rings for the Elven-kings under the sky,
Seven for the Dwarf-lords in their halls of stone,
Nine for Mortal Men doomed to die,
One for the Dark Lord on his dark throne
In the Land of Mordor where the Shadows lie.
One Ring to rule them all, One Ring to find them,
One Ring to bring them all, and in the darkness bind them,
In the Land of Mordor where the Shadows lie.")

lr_token = tokens(lr_text)

kwic(lr_token, "Ring", window=2)

```


## Document Feature Matrix

```{r, echo=TRUE}
sample_token = tokens(data_corpus_inaugural)

sample_dfm = dfm(sample_token)

sample_dfm
```


### DFM Subset

```{r, echo=TRUE}
sample_dfm[1:5,1:7]
```


### DFM Trim

```{r, echo=TRUE}
dfm_trim(sample_dfm, min_termfreq = 30, max_termfreq = 100)
```
### DFM Top Features

```{r, echo=TRUE}
topfeatures(sample_dfm, 5)
```


## Language Options

Quanteda automatically loads stop words from the "Stopwords" package with the "Snowball" collection of 15 languages

```{r, echo=TRUE}
library(stopwords)

stopwords_getsources()  #to see other sources with different languages 

stopwords_getlanguages("snowball") #to see language options of sources


```


```{r, echo=TRUE}
it_poem = ("E chiese al vecchio dammi il pane
Ho poco tempo e troppa fame
E chiese al vecchio dammi il vino
Ho sete e sono un assassino
Gli occhi dischiuse il vecchio al giorno
Non si guardò neppure intorno
Ma versò il vino e spezzò il pane
Per chi diceva ho sete e ho fame")

tokens(it_poem) %>% 
  tokens_remove(stopwords("it"))
```

